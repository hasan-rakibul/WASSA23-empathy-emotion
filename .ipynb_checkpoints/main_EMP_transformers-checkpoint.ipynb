{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2yl9iGYYm07-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers as trf\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from accelerate import notebook_launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/573/rh2942/WASSA-2023-EMP\") # changing dir for evaluation file\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # due to huggingface warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenised_data(filename, tokeniser, train_test):\n",
    "   \n",
    "    input_data = pd.read_csv(filename, header=0, index_col=0)\n",
    "    \n",
    "    if train_test == \"train\":\n",
    "        chosen_data = input_data[[feature_1, feature_2, task]]\n",
    "    elif train_test == \"test\":\n",
    "        chosen_data = input_data[[feature_1, feature_2]]  #test data shouldn't have output label\n",
    "\n",
    "    hugging_dataset = Dataset.from_pandas(chosen_data, preserve_index=False)\n",
    "\n",
    "    tokenised_hugging_dataset = hugging_dataset.map(tokenise, batched=True, remove_columns = [feature_1, feature_2])\n",
    "    \n",
    "    if train_test == \"train\":\n",
    "        tokenised_hugging_dataset = tokenised_hugging_dataset.rename_column(task, \"labels\") # as huggingface requires\n",
    "    \n",
    "    tokenised_hugging_dataset = tokenised_hugging_dataset.with_format(\"torch\")\n",
    "\n",
    "    return tokenised_hugging_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model):\n",
    "    accelerator = Accelerator()\n",
    "    \n",
    "    accelerator.print(f\"{task} prediction\")  #task: \"empathy\" or \"distress\"\n",
    "    \n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    # loss_function = torch.nn.MSELoss()\n",
    "  \n",
    "    trainset = load_tokenised_data(filename=train_filename, tokeniser=tokeniser, train_test=\"train\")\n",
    "       \n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    "    )\n",
    "    \n",
    "    training_steps = NUM_EPOCH * len(trainloader)\n",
    "    lr_scheduler = trf.get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=opt,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=training_steps\n",
    "    )\n",
    "\n",
    "    trainloader, model, opt = accelerator.prepare(\n",
    "        trainloader, model, opt    \n",
    "    )\n",
    "    \n",
    "    for epoch in range(0, NUM_EPOCH):\n",
    "\n",
    "        # Print epoch\n",
    "        accelerator.print(f'Starting epoch {epoch+1}')\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for batch in trainloader:\n",
    "            # Perform forward pass\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            # loss = loss_function(outputs.logits, batch[\"labels\"])\n",
    "\n",
    "            accelerator.backward(loss)\n",
    "        \n",
    "            opt.step()\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        # Process is complete.\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "        accelerator.print(f\"Epoch {epoch}: average loss = {avg_epoch_loss}\")\n",
    "        \n",
    "    \n",
    "    # evaluation on test set\n",
    "    testset = load_tokenised_data(filename=test_filename, tokeniser=tokeniser, train_test=\"test\")\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, shuffle=False, batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    "    )\n",
    "\n",
    "    # testloader = accelerator.prepare(testloader)\n",
    "            \n",
    "    model.eval()\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    for batch in testloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        batch_pred = [item for sublist in outputs.logits.tolist() for item in sublist]  #convert 2D list to 1D\n",
    "        y_pred.extend(batch_pred)\n",
    "  \n",
    "    y_pred_df = pd.DataFrame({task: y_pred})\n",
    "    filename = \"predictions_\" + task + \".tsv\"\n",
    "    y_pred_df.to_csv(filename, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 20\n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "train_filename = \"preprocessed_train.csv\"\n",
    "test_filename = \"preprocessed_test.csv\"\n",
    "\n",
    "#Chosen features\n",
    "feature_1 = 'demographic_essay'\n",
    "feature_2 = 'article'\n",
    "\n",
    "# feature_1 = 'essay_demographic_prompt'\n",
    "# feature_2 = 'article'\n",
    "    \n",
    "# checkpoint = \"bert-base-uncased\"\n",
    "# checkpoint = \"bhadresh-savani/bert-base-uncased-emotion\"\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "# checkpoint = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "tokeniser = trf.AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "#padding=\"longest\" can be deferred to do dynamic padding\n",
    "def tokenise(sentence):\n",
    "    return tokeniser(sentence[feature_1], sentence[feature_2], truncation=True) \n",
    "  # return tokeniser(sentence[\"essay\"], sentence[\"article\"], padding=\"max_length\", max_length=514, truncation=True)   #for Cardiff-emotion one\n",
    "    \n",
    "# data collator due to variable max token length per batch size\n",
    "data_collator = trf.DataCollatorWithPadding(tokenizer = tokeniser)\n",
    "\n",
    "model = trf.AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "empathy prediction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/779 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: average loss = 4.45981561240493\n",
      "Starting epoch 2\n",
      "Epoch 1: average loss = 1.908328813519709\n",
      "Starting epoch 3\n",
      "Epoch 2: average loss = 1.7248383440951607\n",
      "Starting epoch 4\n",
      "Epoch 3: average loss = 1.597538237823904\n",
      "Starting epoch 5\n",
      "Epoch 4: average loss = 0.9531372569460417\n",
      "Starting epoch 6\n",
      "Epoch 5: average loss = 0.49677760310456803\n",
      "Starting epoch 7\n",
      "Epoch 6: average loss = 0.40076955104702894\n",
      "Starting epoch 8\n",
      "Epoch 7: average loss = 0.24228849640527114\n",
      "Starting epoch 9\n",
      "Epoch 8: average loss = 0.16356863237376032\n",
      "Starting epoch 10\n",
      "Epoch 9: average loss = 0.07018695200308778\n",
      "Starting epoch 11\n",
      "Epoch 10: average loss = 0.051487028649865596\n",
      "Starting epoch 12\n",
      "Epoch 11: average loss = 0.03391433773801082\n",
      "Starting epoch 13\n",
      "Epoch 12: average loss = 0.022823318324113568\n",
      "Starting epoch 14\n",
      "Epoch 13: average loss = 0.017042009361867547\n",
      "Starting epoch 15\n",
      "Epoch 14: average loss = 0.01030592015930134\n",
      "Starting epoch 16\n",
      "Epoch 15: average loss = 0.007714364536473206\n",
      "Starting epoch 17\n",
      "Epoch 16: average loss = 0.005633990121948175\n",
      "Starting epoch 18\n",
      "Epoch 17: average loss = 0.005718819747897316\n",
      "Starting epoch 19\n",
      "Epoch 18: average loss = 0.004506121183019749\n",
      "Starting epoch 20\n",
      "Epoch 19: average loss = 0.004431617847912121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task = \"empathy\"\n",
    "notebook_launcher(train_test, (model,), num_processes=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "distress prediction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/779 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: average loss = 4.376671379184996\n",
      "Starting epoch 2\n",
      "Epoch 1: average loss = 2.7903449830375804\n",
      "Starting epoch 3\n",
      "Epoch 2: average loss = 1.6605603583347128\n",
      "Starting epoch 4\n",
      "Epoch 3: average loss = 1.2612255334531015\n",
      "Starting epoch 5\n",
      "Epoch 4: average loss = 0.6370725640195555\n",
      "Starting epoch 6\n",
      "Epoch 5: average loss = 0.3870368437813025\n",
      "Starting epoch 7\n",
      "Epoch 6: average loss = 0.29291493202112995\n",
      "Starting epoch 8\n",
      "Epoch 7: average loss = 0.14886259694425721\n",
      "Starting epoch 9\n",
      "Epoch 8: average loss = 0.06167113888533299\n",
      "Starting epoch 10\n",
      "Epoch 9: average loss = 0.03662283393989165\n",
      "Starting epoch 11\n",
      "Epoch 10: average loss = 0.03110947483412242\n",
      "Starting epoch 12\n",
      "Epoch 11: average loss = 0.01768521182371582\n",
      "Starting epoch 13\n",
      "Epoch 12: average loss = 0.013343499078993253\n",
      "Starting epoch 14\n",
      "Epoch 13: average loss = 0.009250169645290915\n",
      "Starting epoch 15\n",
      "Epoch 14: average loss = 0.005673151922880551\n",
      "Starting epoch 16\n",
      "Epoch 15: average loss = 0.007620463703739117\n",
      "Starting epoch 17\n",
      "Epoch 16: average loss = 0.005779115139598523\n",
      "Starting epoch 18\n",
      "Epoch 17: average loss = 0.005043512829226009\n",
      "Starting epoch 19\n",
      "Epoch 18: average loss = 0.00443802439592534\n",
      "Starting epoch 20\n",
      "Epoch 19: average loss = 0.007277683779963753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task = \"distress\"\n",
    "notebook_launcher(train_test, (model,), num_processes=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the submission file as per requirement\n",
    "predictions_empathy = pd.read_csv(\"predictions_empathy.tsv\", sep='\\t', header=None)\n",
    "predictions_distress = pd.read_csv(\"predictions_distress.tsv\", sep='\\t', header=None)\n",
    "\n",
    "predictions_EMP = pd.concat([predictions_empathy, predictions_distress], axis=1)\n",
    "\n",
    "predictions_EMP.to_csv(\"predictions_EMP.tsv\", sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import pearsonr, calculate_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy: 0.6957\n",
      "Distress: 0.5418\n"
     ]
    }
   ],
   "source": [
    "# Just checking the dev set performance\n",
    "gold_dev = pd.read_csv('./dataset/dev/goldstandard_dev.tsv', sep='\\t', header=None) # no header\n",
    "pearson_empathy = pearsonr(gold_dev.loc[:,0].tolist(), predictions_empathy.loc[:,0].tolist())\n",
    "print(f\"Empathy: {pearson_empathy}\")\n",
    "pearson_distress = pearsonr(gold_dev.loc[:,1].tolist(), predictions_distress.loc[:,0].tolist())\n",
    "print(f\"Distress: {pearson_distress}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import KFold\n",
    "from evaluation import pearsonr, calculate_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_kfold(model):\n",
    "    accelerator = Accelerator()\n",
    "    \n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    training_steps = NUM_EPOCH * len(trainloader)\n",
    "    lr_scheduler = trf.get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=opt,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=training_steps\n",
    "    )\n",
    "  \n",
    "    trainloader_acclerate, model, opt = accelerator.prepare(\n",
    "        trainloader, model, opt    \n",
    "    )  \n",
    "    \n",
    "    for epoch in range(0, NUM_EPOCH):\n",
    "\n",
    "        # Print epoch\n",
    "        accelerator.print(f'Starting epoch {epoch+1}')\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for batch in trainloader_acclerate:\n",
    "            # Perform forward pass\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "#             loss = loss_function(outputs, targets)\n",
    "\n",
    "            accelerator.backward(loss)\n",
    "        \n",
    "            opt.step()\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        # Process is complete.\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "        accelerator.print(f\"Epoch {epoch}: average loss = {avg_epoch_loss}\")\n",
    "    \n",
    "    \n",
    "    # Evaluation\n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "    y_true =[]\n",
    "    y_pred = []\n",
    "\n",
    "    for batch in testloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        y_true.extend(batch['labels'].tolist())\n",
    "\n",
    "        batch_pred = [item for sublist in outputs.logits.tolist() for item in sublist]  #convert 2D list to 1D\n",
    "        y_pred.extend(batch_pred)\n",
    "        \n",
    "    pearson_r = pearsonr(y_true, y_pred)\n",
    "    \n",
    "    accelerator.print('\\n' + checkpoint + ' & ' + str(LEARNING_RATE) + ' & ' + str(BATCH_SIZE) + ' & ' + feature_1 + '-' + feature_2 + ' & ' + str(pearson_r) + ' fold-' + str(fold) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/987 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: average loss = 7.213689975738525\n",
      "Starting epoch 2\n",
      "Epoch 1: average loss = 3.504651494026184\n",
      "Starting epoch 3\n",
      "Epoch 2: average loss = 3.627466974258423\n",
      "Starting epoch 4\n",
      "Epoch 3: average loss = 1.8103101205825807\n",
      "Starting epoch 5\n",
      "Epoch 4: average loss = 1.518955283164978\n",
      "Starting epoch 6\n",
      "Epoch 5: average loss = 1.2208479496836662\n",
      "Starting epoch 7\n",
      "Epoch 6: average loss = 1.2117237094044686\n",
      "Starting epoch 8\n",
      "Epoch 7: average loss = 0.6970827853679658\n",
      "Starting epoch 9\n",
      "Epoch 8: average loss = 0.5291986376047134\n",
      "Starting epoch 10\n",
      "Epoch 9: average loss = 0.2736331722140312\n",
      "\n",
      "bert-large-uncased & 5e-05 & 8 & demographic_essay-article & 0.7977 fold-0\n",
      "\n",
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: average loss = 10.47298833847046\n",
      "Starting epoch 2\n",
      "Epoch 1: average loss = 4.196836357116699\n",
      "Starting epoch 3\n",
      "Epoch 2: average loss = 4.3771005058288575\n",
      "Starting epoch 4\n",
      "Epoch 3: average loss = 4.045954556465149\n",
      "Starting epoch 5\n",
      "Epoch 4: average loss = 3.6713451862335207\n",
      "Starting epoch 6\n",
      "Epoch 5: average loss = 4.030801820755005\n",
      "Starting epoch 7\n",
      "Epoch 6: average loss = 3.761001286506653\n",
      "Starting epoch 8\n",
      "Epoch 7: average loss = 3.821267967224121\n",
      "Starting epoch 9\n",
      "Epoch 8: average loss = 3.99852801322937\n",
      "Starting epoch 10\n",
      "Epoch 9: average loss = 3.6609089183807373\n",
      "\n",
      "bert-large-uncased & 5e-05 & 8 & demographic_essay-article & 0.0469 fold-1\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: average loss = 11.501055421829223\n",
      "Starting epoch 2\n",
      "Epoch 1: average loss = 3.8675417041778566\n",
      "Starting epoch 3\n",
      "Epoch 2: average loss = 3.6557919073104856\n",
      "Starting epoch 4\n",
      "Epoch 3: average loss = 2.618813760280609\n",
      "Starting epoch 5\n",
      "Epoch 4: average loss = 1.6289004373550415\n",
      "Starting epoch 6\n",
      "Epoch 5: average loss = 1.5414224410057067\n",
      "Starting epoch 7\n",
      "Epoch 6: average loss = 0.8820622348785401\n",
      "Starting epoch 8\n",
      "Epoch 7: average loss = 0.5472309976816178\n",
      "Starting epoch 9\n",
      "Epoch 8: average loss = 0.3199688667058945\n",
      "Starting epoch 10\n",
      "Epoch 9: average loss = 0.16565409243106843\n",
      "\n",
      "bert-large-uncased & 5e-05 & 8 & demographic_essay-article & 0.8002 fold-2\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: average loss = 5.486358122825623\n",
      "Starting epoch 2\n",
      "Epoch 1: average loss = 3.3773480463027954\n",
      "Starting epoch 3\n",
      "Epoch 2: average loss = 3.858164029121399\n",
      "Starting epoch 4\n",
      "Epoch 3: average loss = 3.092499678134918\n",
      "Starting epoch 5\n",
      "Epoch 4: average loss = 2.3774873328208925\n",
      "Starting epoch 6\n",
      "Epoch 5: average loss = 2.290995116233826\n",
      "Starting epoch 7\n",
      "Epoch 6: average loss = 2.1909004259109497\n",
      "Starting epoch 8\n",
      "Epoch 7: average loss = 1.3470318806171417\n",
      "Starting epoch 9\n",
      "Epoch 8: average loss = 0.9972421827912331\n",
      "Starting epoch 10\n",
      "Epoch 9: average loss = 0.7596608233451844\n",
      "\n",
      "bert-large-uncased & 5e-05 & 8 & demographic_essay-article & 0.7008 fold-3\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 GPUs.\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: average loss = 8.129480237960815\n",
      "Starting epoch 2\n",
      "Epoch 1: average loss = 3.9551459836959837\n",
      "Starting epoch 3\n",
      "Epoch 2: average loss = 3.8354076099395753\n",
      "Starting epoch 4\n",
      "Epoch 3: average loss = 3.8489742612838747\n",
      "Starting epoch 5\n",
      "Epoch 4: average loss = 5.5751168823242185\n",
      "Starting epoch 6\n",
      "Epoch 5: average loss = 3.7704463481903074\n",
      "Starting epoch 7\n",
      "Epoch 6: average loss = 3.774736123085022\n",
      "Starting epoch 8\n",
      "Epoch 7: average loss = 3.518358378410339\n",
      "Starting epoch 9\n",
      "Epoch 8: average loss = 3.6325153732299804\n",
      "Starting epoch 10\n",
      "Epoch 9: average loss = 3.7241961479187013\n",
      "\n",
      "bert-large-uncased & 5e-05 & 8 & demographic_essay-article & -0.035 fold-4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 10\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "task = \"empathy\"\n",
    "\n",
    "train_dev_filename = \"preprocessed_train_dev.csv\"\n",
    "\n",
    "#Chosen features\n",
    "feature_1 = 'demographic_essay'\n",
    "feature_2 = 'article'\n",
    "\n",
    "# feature_1 = 'essay'\n",
    "# feature_2 = 'demographic'\n",
    "\n",
    "# feature_1 = 'essay'\n",
    "# feature_2 ='article'\n",
    "    \n",
    "# checkpoint = \"bert-base-uncased\"\n",
    "# checkpoint = \"distilbert-base-uncased\"\n",
    "\n",
    "tokeniser = trf.AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "#padding=\"longest\" can be deferred to do dynamic padding\n",
    "def tokenise(sentence):\n",
    "    return tokeniser(sentence[feature_1], sentence[feature_2], truncation=True)\n",
    "    \n",
    "# data collator due to variable max token length per batch size\n",
    "data_collator = trf.DataCollatorWithPadding(tokenizer = tokeniser)\n",
    "\n",
    "train_dev = load_tokenised_data(filename=train_dev_filename, tokeniser=tokeniser, train_test=\"train\")\n",
    "\n",
    "K_FOLD = 5\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "kfold = KFold(n_splits=K_FOLD, shuffle=True)\n",
    "\n",
    "print('--------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(train_dev)):\n",
    "\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_dev,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        collate_fn=data_collator,\n",
    "        sampler=train_subsampler\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        train_dev,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        collate_fn=data_collator,\n",
    "        sampler=test_subsampler\n",
    "    )\n",
    "\n",
    "    # Init the neural network\n",
    "    model = trf.AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=1)\n",
    "\n",
    "    notebook_launcher(train_test_kfold, (model,), num_processes=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_checkpoint = 'gpt2'\n",
    "# prompt_generator = trf.pipeline('text-generation', model=prompt_checkpoint)\n",
    "\n",
    "# def prompt_generate(text):\n",
    "#     \"\"\"\n",
    "#     extend \"text\" to max_length. It will be a list of dictionaries. First item is the first return_sequence. 'generated_text' is self-explanatory.\n",
    "#     \"\"\"\n",
    "#     prompt = prompt_generator(text, max_length=100, num_return_sequences=1)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGrZyLKSjM8T"
   },
   "outputs": [],
   "source": [
    "# checking length after tokenisation\n",
    "\n",
    "# length = []\n",
    "# for i in range(tokenised_hugging_dataset['train'].num_rows):\n",
    "#   length.append(len(tokenised_hugging_dataset['train']['input_ids'][i]))\n",
    "\n",
    "# print(f\"Lengths: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVoIk8rNnokn"
   },
   "outputs": [],
   "source": [
    "# prediction_model.save_pretrained(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LPQQHq1nJcF",
    "outputId": "9b4e8f67-a946-4637-c5a5-fee01adf0033"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# mount_path = '/content/drive'\n",
    "# drive.mount(mount_path)\n",
    "# %cd $mount_path\"/MyDrive/WASSA2023\"\n",
    "\n",
    "# !pip install transformers datasets sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiTJozXmWZwX"
   },
   "source": [
    "## Training by Huggingface API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NndR8auWhHQ"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yX5BheZmm08M"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3At0OTim08M"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"empathy-transformer\",\n",
    "                                  logging_strategy=\"epoch\",\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  per_device_eval_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  # learning_rate=2e-5,\n",
    "                                  save_total_limit=2,\n",
    "                                  save_strategy='no',\n",
    "                                  load_best_model_at_end=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=empathy_prediction,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenised_hugging_dataset[\"train\"],\n",
    "    eval_dataset=tokenised_hugging_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokeniser,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "id": "wmpZg3xRm08M",
    "outputId": "73b55f15-80ac-40db-dbba-f2346987f5a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/117 00:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.415700</td>\n",
       "      <td>3.094043</td>\n",
       "      <td>1.758989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.160800</td>\n",
       "      <td>2.747570</td>\n",
       "      <td>1.657580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.413400</td>\n",
       "      <td>2.890623</td>\n",
       "      <td>1.700183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=117, training_loss=2.329951457488231, metrics={'train_runtime': 30.014, 'train_samples_per_second': 62.271, 'train_steps_per_second': 3.898, 'total_flos': 76837223949486.0, 'train_loss': 2.329951457488231, 'epoch': 3.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "HYa6E8PQ0g5o",
    "outputId": "409925e8-7049-4696-b191-2a93437f3ed8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_pred, _, _ = trainer.predict(tokenised_hugging_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "\n",
    "    device = \"cuda:0\"\n",
    "    if torch.cuda.device_count() > 1:\n",
    "            model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "    # device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    # model.to(device)\n",
    "    \n",
    "    # criterion = torch.nn.MSELoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    trainset = load_tokenised_data(raw_data, tokeniser) #train\n",
    "       \n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        trainset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    "    )\n",
    "    \n",
    "    training_steps = NUM_EPOCH * len(train_dataloader)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=1, gamma=0.1)\n",
    "    lr_scheduler = trf.get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=opt,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=training_steps\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss \n",
    "            # loss = criterion(outputs.logits, batch['labels'])\n",
    "\n",
    "            loss.backward()    \n",
    "            opt.step()\n",
    "            lr_scheduler.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "        print(f\"Epoch {epoch}: average loss = {avg_epoch_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "04GpI_v-P0o1"
   },
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    model = trf.AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=1)\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    opt = torch.optim.AdamW(prediction_model.parameters(), lr=config[\"learning_rate\"], momentum=0.9)\n",
    "    \n",
    "    train_dev = load_tokenised_data(filename=train_dev_filename, tokeniser=tokeniser, train_test=\"train\")\n",
    "    \n",
    "    train_portion = int(len(train_dev) * 0.8)\n",
    "    validation_portion = len(train_dev) - train_portion\n",
    "    train_subset, val_subset = torch.utils.data.random_split(train_dev, [train_portion, validation_portion])\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_subset, shuffle=True, batch_size=int(config[\"batch_size\"]), collate_fn=data_collator\n",
    "    )\n",
    "    \n",
    "    validation_dataloader = torch.utils.data.DataLoader(\n",
    "        validation_subset, shuffle=True, batch_size=int(config[\"batch_size\"]), collate_fn=data_collator\n",
    "    )\n",
    "    \n",
    "    training_steps = NUM_EPOCH * len(train_dataloader)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=1, gamma=0.1)\n",
    "    lr_scheduler = trf.get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=opt,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=training_steps\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss \n",
    "            # loss = criterion(outputs.logits, batch['labels'])\n",
    "\n",
    "            loss.backward()    \n",
    "            opt.step()\n",
    "            lr_scheduler.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "        tune.report(loss=avg_epoch_loss)\n",
    "\n",
    "        # Evaluation    \n",
    "        # model.eval()\n",
    "\n",
    "        y_true =[]\n",
    "        y_pred = []\n",
    "        val_loss = 0.0\n",
    "        val_step = 0\n",
    "\n",
    "        for batch in validation_dataloader:\n",
    "            with torch.no_grad():\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "\n",
    "                y_true.extend(batch['labels'].tolist())\n",
    "                batch_pred = [item for sublist in outputs.logits.tolist() for item in sublist]  #convert 2D list to 1D\n",
    "                y_pred.extend(batch_pred)\n",
    "                pearson_r = pearsonr(y_true, y_pred)\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "                \n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=pearson_r)\n",
    "    \n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 01:25:44,553\tWARNING resource_updater.py:50 -- Cluster resources not detected or are 0. Attempt #2...\n",
      "2023-04-24 01:25:45,055\tWARNING resource_updater.py:50 -- Cluster resources not detected or are 0. Attempt #3...\n",
      "2023-04-24 01:25:45,557\tWARNING resource_updater.py:50 -- Cluster resources not detected or are 0. Attempt #4...\n",
      "2023-04-24 01:25:46,060\tWARNING resource_updater.py:50 -- Cluster resources not detected or are 0. Attempt #5...\n",
      "2023-04-24 01:25:46,562\tWARNING resource_updater.py:63 -- Cluster resources cannot be detected or are 0. You can resume this experiment by passing in `resume=True` to `run`.\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "Traceback (most recent call last):\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py\", line 900, in _wait_and_handle_event\n    event = self.trial_executor.get_next_executor_event(\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1183, in get_next_executor_event\n    self._stage_and_update_status(live_trials)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 324, in _stage_and_update_status\n    self._resource_manager.request_resources(resource_request=resource_request)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/air/execution/resources/placement_group.py\", line 143, in request_resources\n    future = pg.ready()\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/placement_group.py\", line 81, in ready\n    ).remote(self)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/remote_function.py\", line 226, in remote\n    return func_cls._remote(args=args, kwargs=kwargs, **updated_options)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py\", line 307, in _invocation_remote_span\n    return method(self, args, kwargs, *_args, **_kwargs)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/remote_function.py\", line 412, in _remote\n    return invocation(args, kwargs)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/remote_function.py\", line 387, in invocation\n    object_refs = worker.core_worker.submit_task(\n  File \"python/ray/_raylet.pyx\", line 1969, in ray._raylet.CoreWorker.submit_task\n  File \"python/ray/_raylet.pyx\", line 1973, in ray._raylet.CoreWorker.submit_task\n  File \"python/ray/_raylet.pyx\", line 425, in ray._raylet.prepare_args_and_increment_put_refs\n  File \"python/ray/_raylet.pyx\", line 416, in ray._raylet.prepare_args_and_increment_put_refs\n  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.prepare_args_internal\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/_private/worker.py\", line 539, in get_serialization_context\n    context_map[job_id] = serialization.SerializationContext(self)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/_private/serialization.py\", line 135, in __init__\n    serialization_addons.apply(self)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/serialization_addons.py\", line 58, in apply\n    register_pydantic_serializer(serialization_context)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/serialization_addons.py\", line 21, in register_pydantic_serializer\n    pydantic.fields.ModelField,\nAttributeError: module 'pydantic.fields' has no attribute 'ModelField'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:900\u001b[0m, in \u001b[0;36mTrialRunner._wait_and_handle_event\u001b[0;34m(self, next_trial)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;66;03m# Single wait of entire tune loop.\u001b[39;00m\n\u001b[0;32m--> 900\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_executor_event\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_live_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_trial\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m _ExecutorEventType\u001b[38;5;241m.\u001b[39mPG_READY:\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py:1183\u001b[0m, in \u001b[0;36mRayTrialExecutor.get_next_executor_event\u001b[0;34m(self, live_trials, next_trial_exists)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# First update status of staged placement groups\u001b[39;00m\n\u001b[0;32m-> 1183\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stage_and_update_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlive_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;66;03m###################################################################\u001b[39;00m\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# when next_trial_exists and there are cached resources\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;66;03m# a next trial to run, we return `PG_READY` future for trial\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;66;03m# runner. The next trial can then be scheduled on this PG.\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py:324\u001b[0m, in \u001b[0;36mRayTrialExecutor._stage_and_update_status\u001b[0;34m(self, trials)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_staged_resources[trial\u001b[38;5;241m.\u001b[39mplacement_group_factory] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_resources\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_request\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_manager\u001b[38;5;241m.\u001b[39mupdate_state()\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/air/execution/resources/placement_group.py:143\u001b[0m, in \u001b[0;36mPlacementGroupResourceManager.request_resources\u001b[0;34m(self, resource_request)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_to_staged_pgs[resource_request]\u001b[38;5;241m.\u001b[39madd(pg)\n\u001b[0;32m--> 143\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[43mpg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mready\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_staging_future_to_pg[future] \u001b[38;5;241m=\u001b[39m pg\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/placement_group.py:81\u001b[0m, in \u001b[0;36mPlacementGroup.ready\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbundle_cache) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m, (\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mready() cannot be called on placement group object with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbundle length == 0, current bundle length: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbundle_cache)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbundle_reservation_check\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduling_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPlacementGroupSchedulingStrategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplacement_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mBUNDLE_RESOURCE_LABEL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/remote_function.py:226\u001b[0m, in \u001b[0;36mRemoteFunction.options.<locals>.FuncWrapper.remote\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremote\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remote\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mupdated_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py:307\u001b[0m, in \u001b[0;36m_tracing_task_invocation.<locals>._invocation_remote_span\u001b[0;34m(self, args, kwargs, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ray_trace_ctx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ray_trace_ctx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/remote_function.py:412\u001b[0m, in \u001b[0;36mRemoteFunction._remote\u001b[0;34m(self, args, kwargs, **task_options)\u001b[0m\n\u001b[1;32m    410\u001b[0m     invocation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decorator(invocation)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minvocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/remote_function.py:387\u001b[0m, in \u001b[0;36mRemoteFunction._remote.<locals>.invocation\u001b[0;34m(args, kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_cross_language\n\u001b[1;32m    386\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross language remote function cannot be executed locally.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 387\u001b[0m object_refs \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_language\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_descriptor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_exception_allowlist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebugger_breakpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized_runtime_env_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# Reset worker's debug context from the last \"remote\" command\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# (which applies only to this .remote call).\u001b[39;00m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:1969\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.submit_task\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:1973\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.submit_task\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:425\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_and_increment_put_refs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:416\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_and_increment_put_refs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:462\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_internal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/_private/worker.py:539\u001b[0m, in \u001b[0;36mWorker.get_serialization_context\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 539\u001b[0m         context_map[job_id] \u001b[38;5;241m=\u001b[39m \u001b[43mserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializationContext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context_map[job_id]\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/_private/serialization.py:135\u001b[0m, in \u001b[0;36mSerializationContext.__init__\u001b[0;34m(self, worker)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_cloudpickle_reducer(\n\u001b[1;32m    132\u001b[0m     ObjectRefGenerator, object_ref_generator_reducer\n\u001b[1;32m    133\u001b[0m )\n\u001b[0;32m--> 135\u001b[0m \u001b[43mserialization_addons\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/serialization_addons.py:58\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(serialization_context)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;129m@DeveloperAPI\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(serialization_context):\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mregister_pydantic_serializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserialization_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     register_starlette_serializer(serialization_context)\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/serialization_addons.py:21\u001b[0m, in \u001b[0;36mregister_pydantic_serializer\u001b[0;34m(serialization_context)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Pydantic's Cython validators are not serializable.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# https://github.com/cloudpipe/cloudpickle/issues/408\u001b[39;00m\n\u001b[1;32m     20\u001b[0m serialization_context\u001b[38;5;241m.\u001b[39m_register_cloudpickle_serializer(\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mpydantic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModelField\u001b[49m,\n\u001b[1;32m     22\u001b[0m     custom_serializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m o: {\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: o\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# outer_type_ is the original type for ModelFields,\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m# while type_ can be updated later with the nested type\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# like int for List[int].\u001b[39;00m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype_\u001b[39m\u001b[38;5;124m\"\u001b[39m: o\u001b[38;5;241m.\u001b[39mouter_type_,\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_validators\u001b[39m\u001b[38;5;124m\"\u001b[39m: o\u001b[38;5;241m.\u001b[39mclass_validators,\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m\"\u001b[39m: o\u001b[38;5;241m.\u001b[39mmodel_config,\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m: o\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_factory\u001b[39m\u001b[38;5;124m\"\u001b[39m: o\u001b[38;5;241m.\u001b[39mdefault_factory,\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequired\u001b[39m\u001b[38;5;124m\"\u001b[39m: o\u001b[38;5;241m.\u001b[39mrequired,\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malias\u001b[39m\u001b[38;5;124m\"\u001b[39m: o\u001b[38;5;241m.\u001b[39malias,\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfield_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: o\u001b[38;5;241m.\u001b[39mfield_info,\n\u001b[1;32m     35\u001b[0m     },\n\u001b[1;32m     36\u001b[0m     custom_deserializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m kwargs: pydantic\u001b[38;5;241m.\u001b[39mfields\u001b[38;5;241m.\u001b[39mModelField(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[1;32m     37\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pydantic.fields' has no attribute 'ModelField'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mschedulers\u001b[38;5;241m.\u001b[39mASHAScheduler(\n\u001b[1;32m      7\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     reduction_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m reporter \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mCLIReporter(metric_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_reporter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreporter\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m analysis\u001b[38;5;241m.\u001b[39mget_best_trial(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial config: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_trial\u001b[38;5;241m.\u001b[39mconfig))\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/tune.py:756\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, trial_executor, _experiment_checkpoint_dir, _remote, _remote_string_queue)\u001b[0m\n\u001b[1;32m    749\u001b[0m progress_reporter\u001b[38;5;241m.\u001b[39msetup(\n\u001b[1;32m    750\u001b[0m     start_time\u001b[38;5;241m=\u001b[39mtune_start,\n\u001b[1;32m    751\u001b[0m     total_samples\u001b[38;5;241m=\u001b[39msearch_alg\u001b[38;5;241m.\u001b[39mtotal_samples,\n\u001b[1;32m    752\u001b[0m     metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[1;32m    753\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    754\u001b[0m )\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mis_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m--> 756\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_verbosity(Verbosity\u001b[38;5;241m.\u001b[39mV1_EXPERIMENT):\n\u001b[1;32m    758\u001b[0m         _report_progress(runner, progress_reporter)\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:957\u001b[0m, in \u001b[0;36mTrialRunner.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_trial:\n\u001b[1;32m    955\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot new trial to run: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnext_trial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_and_handle_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_trial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_experiment_if_needed()\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:936\u001b[0m, in \u001b[0;36mTrialRunner._wait_and_handle_event\u001b[0;34m(self, next_trial)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TuneError(traceback\u001b[38;5;241m.\u001b[39mformat_exc())\n",
      "\u001b[0;31mTuneError\u001b[0m: Traceback (most recent call last):\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py\", line 900, in _wait_and_handle_event\n    event = self.trial_executor.get_next_executor_event(\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1183, in get_next_executor_event\n    self._stage_and_update_status(live_trials)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 324, in _stage_and_update_status\n    self._resource_manager.request_resources(resource_request=resource_request)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/air/execution/resources/placement_group.py\", line 143, in request_resources\n    future = pg.ready()\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/placement_group.py\", line 81, in ready\n    ).remote(self)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/remote_function.py\", line 226, in remote\n    return func_cls._remote(args=args, kwargs=kwargs, **updated_options)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py\", line 307, in _invocation_remote_span\n    return method(self, args, kwargs, *_args, **_kwargs)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/remote_function.py\", line 412, in _remote\n    return invocation(args, kwargs)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/remote_function.py\", line 387, in invocation\n    object_refs = worker.core_worker.submit_task(\n  File \"python/ray/_raylet.pyx\", line 1969, in ray._raylet.CoreWorker.submit_task\n  File \"python/ray/_raylet.pyx\", line 1973, in ray._raylet.CoreWorker.submit_task\n  File \"python/ray/_raylet.pyx\", line 425, in ray._raylet.prepare_args_and_increment_put_refs\n  File \"python/ray/_raylet.pyx\", line 416, in ray._raylet.prepare_args_and_increment_put_refs\n  File \"python/ray/_raylet.pyx\", line 462, in ray._raylet.prepare_args_internal\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/_private/worker.py\", line 539, in get_serialization_context\n    context_map[job_id] = serialization.SerializationContext(self)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/_private/serialization.py\", line 135, in __init__\n    serialization_addons.apply(self)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/serialization_addons.py\", line 58, in apply\n    register_pydantic_serializer(serialization_context)\n  File \"/scratch/jr19/rh2942/miniconda3/lib/python3.10/site-packages/ray/util/serialization_addons.py\", line 21, in register_pydantic_serializer\n    pydantic.fields.ModelField,\nAttributeError: module 'pydantic.fields' has no attribute 'ModelField'\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"learning_rate\": tune.loguniform(6e-5, 2e-5),\n",
    "    \"batch_size\": tune.choice([4, 8, 16])\n",
    "}\n",
    "\n",
    "scheduler = tune.schedulers.ASHAScheduler(\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    max_t = 10,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "reporter = tune.CLIReporter(metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "\n",
    "analysis = tune.run(\n",
    "    train,\n",
    "    config=config,\n",
    "    num_samples=10,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter\n",
    ")\n",
    "\n",
    "best_trial = analysis.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
    "print(\"Best trial final validation accuracy: {}\".format(best_trial.last_result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "019a2b50e92944b9a654adfe21b29e1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "068aa307f71948f4868571800fc62cf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d880320df754284ac7e1fd383fcab47",
      "placeholder": "",
      "style": "IPY_MODEL_a2bc9fc3920541328bf3c7c11af2dbd0",
      "value": "100%"
     }
    },
    "0a80e4bcdb7d44fbac9a88332e253072": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b4163ac34b6421f8b0536b42a52e0de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de07c72bb8d34e8199bafaedf3e71c09",
      "placeholder": "",
      "style": "IPY_MODEL_4fcdb523470f4f4383b55c2e7ec667b5",
      "value": " 466k/466k [00:00&lt;00:00, 6.46MB/s]"
     }
    },
    "0dd711d8ebd24bd9a1f48b42466f18cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12f8314a3be74e55a821f0db69328a2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14957b7f8aa9461baff2f47a96f943ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a294955d69e45868558f92035a18551",
      "max": 789,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16e8d2189af04c3c9a479839f488a771",
      "value": 789
     }
    },
    "14b4dabadf654bb6b4465fc815a272fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_82a44c6bcff8436b866b3b76e702479a",
       "IPY_MODEL_4f3df4ba7e264a8daa8cb50caf5f15e9",
       "IPY_MODEL_90f877b9048c4cc1b9de76962f9e43ad"
      ],
      "layout": "IPY_MODEL_a82f5705e0904a9ba8037a2296d86fd9"
     }
    },
    "15a86a2541424587be438cf70c5aa6e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbcd44c47a024ea9b66b80ab95473609",
      "max": 297,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_348ef813fce44b61bfa9a27def8710af",
      "value": 296
     }
    },
    "16e8d2189af04c3c9a479839f488a771": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "193f8daf04e14821bfaf5dd8dd7fcbfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_725baeede119400bb60e0260b4f6eaaa",
      "placeholder": "",
      "style": "IPY_MODEL_bf3a804442194bbcb01e44be2c5fa8bd",
      "value": "Downloading ()okenizer_config.json: 100%"
     }
    },
    "1dc3434a24704300b8e81a198b5c5c6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ea2df5178c64608902dc6d15da6ea60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2070b8cb9a1e4eafba8c218356ecf221": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20c29762139746929d4753631290576b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d62ba9b0d50345e2a664baba14922271",
      "placeholder": "",
      "style": "IPY_MODEL_94b82396e12f42a2bef2e82a451c9f9b",
      "value": " 198/198 [00:01&lt;00:00, 157.08 examples/s]"
     }
    },
    "22ee34678ea54e7b80653fefc3a9635a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "272d022212364b8e927676b9d9fc1ff8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29884fbb6c294dd8a11f28a037611ced": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8b24de0478544f1a09b999a9c02c5b8",
      "placeholder": "",
      "style": "IPY_MODEL_1dc3434a24704300b8e81a198b5c5c6d",
      "value": "Map: 100%"
     }
    },
    "2a294955d69e45868558f92035a18551": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32cbb3cd933f4e38b3e6a6c50297a7bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "348ef813fce44b61bfa9a27def8710af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3865d7877c0e4e4ea007fa2503e7fd70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ace17fab80b4c24a385b6f2d7800c89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1e606b6b3454cada697ab5b3ffd5bce",
      "placeholder": "",
      "style": "IPY_MODEL_66286e946704463bb1fccdc2da9d9354",
      "value": "Map: 100%"
     }
    },
    "3b72b5cb531b493d8d4fb05ca7236e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c3504a0b63d490183ed68c90036909a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42fef05fede34e988a160effc741919b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44306231d1794ac0b909e4aea07e2567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ac383ecdbaea4821a5c9c4ef7f2ea1f4",
       "IPY_MODEL_62b78baba7c74e6799fb9828a85b20fb",
       "IPY_MODEL_0b4163ac34b6421f8b0536b42a52e0de"
      ],
      "layout": "IPY_MODEL_2070b8cb9a1e4eafba8c218356ecf221"
     }
    },
    "4f3df4ba7e264a8daa8cb50caf5f15e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12f8314a3be74e55a821f0db69328a2c",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68dae4186c6547448e291b0051a3d9d0",
      "value": 483
     }
    },
    "4fcdb523470f4f4383b55c2e7ec667b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59c0f2c0e8854416b55296c8c2aef348": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b3e00f23dfa48d9be97c35a240a0de4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cbd0ab882834402ad470508f32d50ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61ebcac2245c4367865bf312cf2f4ea5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cea4f1d92404188bae5c398ab9516b6",
      "max": 198,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_019a2b50e92944b9a654adfe21b29e1a",
      "value": 198
     }
    },
    "62b78baba7c74e6799fb9828a85b20fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e90833cea974833bb9bea31d16e0f9a",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a80e4bcdb7d44fbac9a88332e253072",
      "value": 466062
     }
    },
    "66286e946704463bb1fccdc2da9d9354": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67e526da2b694b4c88ea2fc58786a883": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68dae4186c6547448e291b0051a3d9d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c7beac6d30141d3823f1656b005d3bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f114ef33880449d990af367f4503b5e",
       "IPY_MODEL_f0d73b96fe034e2d89fabc2c1219c3de",
       "IPY_MODEL_6eedda0d4565441ab8271d16e090ebdb"
      ],
      "layout": "IPY_MODEL_42fef05fede34e988a160effc741919b"
     }
    },
    "6d880320df754284ac7e1fd383fcab47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6da252cb0aef43649ca4a95b3b2693b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83c517dffde24930a433b83da7082f2a",
      "placeholder": "",
      "style": "IPY_MODEL_740667ba16374193a4c64df1fa33b5b2",
      "value": " 296/297 [02:00&lt;00:00,  2.52it/s]"
     }
    },
    "6eccde8ea48949869d021728def1caed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_193f8daf04e14821bfaf5dd8dd7fcbfc",
       "IPY_MODEL_d31e5358e5234b07bf2b2e11095edbc3",
       "IPY_MODEL_d64331cd462b47b7906e547106648f2f"
      ],
      "layout": "IPY_MODEL_22ee34678ea54e7b80653fefc3a9635a"
     }
    },
    "6eedda0d4565441ab8271d16e090ebdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f93ca224666845ebae516c50f6378837",
      "placeholder": "",
      "style": "IPY_MODEL_32cbb3cd933f4e38b3e6a6c50297a7bb",
      "value": " 232k/232k [00:00&lt;00:00, 3.06MB/s]"
     }
    },
    "6f114ef33880449d990af367f4503b5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f277390ce6874c3f8b06d1dddd6fb1ba",
      "placeholder": "",
      "style": "IPY_MODEL_7c3548f5bc3642a8b7d6cb8aa0d10f47",
      "value": "Downloading ()solve/main/vocab.txt: 100%"
     }
    },
    "725baeede119400bb60e0260b4f6eaaa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73536ab0ddab4fe990c33dbd455b0274": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "740667ba16374193a4c64df1fa33b5b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c3548f5bc3642a8b7d6cb8aa0d10f47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7da93c6d1f084d6b996e88d5fcd667df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "7e1a334fe26d430b9d4815273ee42e7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e90833cea974833bb9bea31d16e0f9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "820dcc325318428cbb5a9d59361d10e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3ace17fab80b4c24a385b6f2d7800c89",
       "IPY_MODEL_14957b7f8aa9461baff2f47a96f943ed",
       "IPY_MODEL_85b63caf30a84ad7af31d86a241f2a50"
      ],
      "layout": "IPY_MODEL_7da93c6d1f084d6b996e88d5fcd667df"
     }
    },
    "82a44c6bcff8436b866b3b76e702479a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b5911a6ae344228a258f088ab11c754",
      "placeholder": "",
      "style": "IPY_MODEL_f87a2029b1404a3f9ba6096254667aca",
      "value": "Downloading ()lve/main/config.json: 100%"
     }
    },
    "83c517dffde24930a433b83da7082f2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85b63caf30a84ad7af31d86a241f2a50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_faaa799608084a9bbf742de4a7e5e854",
      "placeholder": "",
      "style": "IPY_MODEL_ccdca3ae922b444d8e30214671c3b11b",
      "value": " 789/789 [00:04&lt;00:00, 179.95 examples/s]"
     }
    },
    "8660c09021cd425782b83c9adf5b7f66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b5911a6ae344228a258f088ab11c754": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cea4f1d92404188bae5c398ab9516b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90f877b9048c4cc1b9de76962f9e43ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8660c09021cd425782b83c9adf5b7f66",
      "placeholder": "",
      "style": "IPY_MODEL_3865d7877c0e4e4ea007fa2503e7fd70",
      "value": " 483/483 [00:00&lt;00:00, 13.7kB/s]"
     }
    },
    "94b82396e12f42a2bef2e82a451c9f9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fb118a6e6f9413780d804ef7fdea87b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a2bc9fc3920541328bf3c7c11af2dbd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a82f5705e0904a9ba8037a2296d86fd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac383ecdbaea4821a5c9c4ef7f2ea1f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73536ab0ddab4fe990c33dbd455b0274",
      "placeholder": "",
      "style": "IPY_MODEL_1ea2df5178c64608902dc6d15da6ea60",
      "value": "Downloading ()/main/tokenizer.json: 100%"
     }
    },
    "b472a66604e4452f84607382edc5538f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_29884fbb6c294dd8a11f28a037611ced",
       "IPY_MODEL_61ebcac2245c4367865bf312cf2f4ea5",
       "IPY_MODEL_20c29762139746929d4753631290576b"
      ],
      "layout": "IPY_MODEL_9fb118a6e6f9413780d804ef7fdea87b"
     }
    },
    "b4f3c43d55d047e1ad04ae26d5218d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_068aa307f71948f4868571800fc62cf2",
       "IPY_MODEL_15a86a2541424587be438cf70c5aa6e6",
       "IPY_MODEL_6da252cb0aef43649ca4a95b3b2693b4"
      ],
      "layout": "IPY_MODEL_67e526da2b694b4c88ea2fc58786a883"
     }
    },
    "b8b24de0478544f1a09b999a9c02c5b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba21b96030244576a58b76351b0a47fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bbcd44c47a024ea9b66b80ab95473609": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf3a804442194bbcb01e44be2c5fa8bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c527826727434424bbdb8d7054d0d576": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ccdca3ae922b444d8e30214671c3b11b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1e606b6b3454cada697ab5b3ffd5bce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d31e5358e5234b07bf2b2e11095edbc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbccf1a820a54f2c89f4293058c86966",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c527826727434424bbdb8d7054d0d576",
      "value": 28
     }
    },
    "d62ba9b0d50345e2a664baba14922271": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d64331cd462b47b7906e547106648f2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b3e00f23dfa48d9be97c35a240a0de4",
      "placeholder": "",
      "style": "IPY_MODEL_7e1a334fe26d430b9d4815273ee42e7e",
      "value": " 28.0/28.0 [00:00&lt;00:00, 545B/s]"
     }
    },
    "dbccf1a820a54f2c89f4293058c86966": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de07c72bb8d34e8199bafaedf3e71c09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df6b9ab2bf92425f9717887db3ad00d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e86332f93e44445ca544f8033c3303e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df6b9ab2bf92425f9717887db3ad00d5",
      "placeholder": "",
      "style": "IPY_MODEL_0dd711d8ebd24bd9a1f48b42466f18cf",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "e9fe6542022e46b7b9e3ff4dc93a5fbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_272d022212364b8e927676b9d9fc1ff8",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b72b5cb531b493d8d4fb05ca7236e8e",
      "value": 267967963
     }
    },
    "ed9e36ac18104cf6b86198e74c8fc161": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e86332f93e44445ca544f8033c3303e7",
       "IPY_MODEL_e9fe6542022e46b7b9e3ff4dc93a5fbc",
       "IPY_MODEL_fbfeddc7d019441f870958682a8af628"
      ],
      "layout": "IPY_MODEL_59c0f2c0e8854416b55296c8c2aef348"
     }
    },
    "f0d73b96fe034e2d89fabc2c1219c3de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cbd0ab882834402ad470508f32d50ae",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ba21b96030244576a58b76351b0a47fd",
      "value": 231508
     }
    },
    "f277390ce6874c3f8b06d1dddd6fb1ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f63f4ddbd4e1401fa5550e6c86243904": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f87a2029b1404a3f9ba6096254667aca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f93ca224666845ebae516c50f6378837": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "faaa799608084a9bbf742de4a7e5e854": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbfeddc7d019441f870958682a8af628": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f63f4ddbd4e1401fa5550e6c86243904",
      "placeholder": "",
      "style": "IPY_MODEL_3c3504a0b63d490183ed68c90036909a",
      "value": " 268M/268M [00:02&lt;00:00, 91.6MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
